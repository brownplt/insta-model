\documentclass[english,cleveref,submission]{programming}

%% Thesis:
%%  1. Static Python is sound, fast, and practical
%%  2. SP has unique features and restrictions for speed
%%  3. Gradual soundness is a feature: start with weak types and eventually migrate to checked types

% > Here’s the thing: I think this is the sort of thing an academic might say “oh,
% > this is too much work, it’d never work” But in fact it looks like they seem to
% > be making it work -- Shriram 2021-09-30

%% TODO before submission
%% - look out for PROGRESSIVE TYPES~\cite{pqk-onward-2012}, where changing annotations
%%   helps the static checker find new errors. ChkDict is one example.
%% - idea: formalism would be a SUBSET of Nom, so our burden of proof is low
%% - what are the idiomatic base SP types ... int or Int ?
%% - choose words: static vs typed, nonstatic vs dynamic vs untyped

%% TODO after submission, before camera-ready
%% - 

\newcommand{\shorturl}[2]{\href{#1#2}{#2}}
\newcommand{\SP}{Static Python}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\defeq}{=}
\newcommand{\mfeq}{=}
\newcommand{\langmid}{\mathrel{\mathbf{\Big\vert}}}
\newenvironment{langarray}{\(\def\arraystretch{1.5}\begin{array}{l@{\hspace{2mm}}c@{\hspace{2mm}}l}}{\end{array}\)}

  \newcommand{\bmname}[1]{\textbf{#1}}
\newcommand{\typefont}[1]{\mathsf{#1}}
\newcommand{\paramtype}[2]{#1[#2]}
\newcommand{\sptype}{\typefont{T}}
\newcommand{\sptclass}{\typefont{C}}
\newcommand{\sptint}{\typefont{Int}}
\newcommand{\sptfloat}{\typefont{Float}}
\newcommand{\sptdyn}{\typefont{Dynamic}}
\newcommand{\sptobject}{\typefont{Object}}
\newcommand{\sptnone}{\typefont{NoneType}}
\newcommand{\sptinstanceof}[1]{\paramtype{\typefont{Instance}}{#1}}
\newcommand{\sptfun}[2]{#1 \rightarrow #2}
\newcommand{\sptunion}[2]{#1 \cup #2}
\newcommand{\sptoptional}[1]{\paramtype{\typefont{Optional}}{#1}}
\newcommand{\sptrawpydict}{\typefont{PyDict}}
\newcommand{\sptpydict}[2]{\paramtype{\sptrawpydict}{#1, #2}}
\newcommand{\sptchkdict}[2]{\paramtype{\typefont{ChkDict}}{#1, #2}}

\newcommand{\spexpr}{e}
\newcommand{\spvalue}{v}

\newcommand{\sprred}{\rightarrow^*}

\newcommand{\mfapply}[2]{#1\,(#2)}
\newcommand{\mffont}[1]{\mathit{#1}}
\newcommand{\mftypeF}[1]{\mfapply{\mffont{F}}{#1}}
\newcommand{\mfopt}[1]{\mfapply{\mffont{opt}}{#1}}

\newcommand{\sperror}{\mathrm{Error}}

%\overfullrule=1mm

%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT}
%\SetWatermarkScale{1}

%% BEGIN tobias pape 2021-11-06
\makeatletter
\newcommand*\abstractpart[1]{\unskip\par\noindent{\firamedium\color{P@GrayFG}{#1}}\enspace}
\makeatother
%% END

%\usepackage{cleveref}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage[backend=biber]{biblatex}
\addbibresource{bg.bib}

\begin{document}

\title{Gradual Soundness: Lessons from Static Python}
%% ... types make things fast?
%% ... gradual migratory progressive soundness

%\titlerunning{short title}

\author[a]{Kuang-Chen Lu}
\authorinfo{(\email{LuKuangchen1024@gmail.com}) is a PhD student at Brown University.}
\affiliation[a]{Brown University, Providence, RI, USA}
\author[a]{Ben Greenman}
\authorinfo{(\email{benjamin.l.greenman@gmail.com}) is a PLT member and a postdoc at Brown University.}
\author[b]{Carl Meyer}
\authorinfo{(\email{carljm@fb.com}) FILL}
\affiliation[b]{Facebook, Inc.}
\author[b]{Dino Viehland}
\authorinfo{(\email{dinoviehland@fb.com}) FILL}
\author[a]{Shriram Krishnamurthi}
\authorinfo{(\email{shriram@brown.edu}) is the Vice President of Programming Languages (no, not really) at Brown University.}

%\authorrunning{K-C. Lu, B. Greenman, C. Meyer, D. Viehland, S. Krishnamurthi}

\keywords{gradual typing, migratory typing}

\begin{CCSXML}
\end{CCSXML}
% \ccsdesc[100]{FILL}
%TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\paperdetails{
  %% perspective options are: art, sciencetheoretical, scienceempirical, engineering.
  perspective=scienceempirical,
  %% State one or more areas, separated by a comma. (see 2.2)
  %% Please see list of areas in http://programming-journal.org/cfp/
  %% The list is open-ended, so use other areas if yours is/are not listed.
  area={Database programming, General-purpose programming, Program
    verification, Programming education},
  %% License options include: cc-by (default), cc-by-nc
  % license=cc-by,
}

\maketitle

\begin{abstract}
%  Soundness, migratory typing.
%  Novel run-time check strategy, combines concrete and transient for ergonomics.

  \let\paragraph\abstractpart

  \paragraph{Context}
  % What is the broad context of the work? What is
  % the importance of the general research area?
  Gradually-typed languages allow typed and untyped code to interoperate,
  but typically come with some kind of drawback.
  In some languages, the types are unreliable;
  in others, communication across type boundaries can be extremely expensive;
  and still others allow only limited forms of interoperability.
  The research community is actively seeking a sound, fast, and expressive
  approach to gradual typing.

  %% TODO acknowlegde the success of new language / tracing JIT approaches

  \paragraph{Inquiry}
  % What problem or question does the paper
  % address? How has this problem or question been
  % addressed by others (if at all)?
  This paper describes \SP{}, a language developed by engineers at Instagram
  that has proven itself sound, fast, and reasonably expressive in production.
  \SP{}'s approach to gradual types is essentially a programmer-tunable combination of
  the \emph{concrete}\/ and \emph{transient}\/ approaches from the literature.
  Concrete types provide soundness in an efficient but difficult-to-use way.
  Transient types are sound in a shallow sense and easier to use; they help
  to bridge the gap between untyped code and typed concrete code.

  \paragraph{Approach}
  % What was done that unveiled new knowledge?
  In collaboration with the \SP{} team, we have evaluated the language
  as it exists today and developed a model to capture the essence of its
  approach to gradual types.
  We drew upon personal communications, bug reports, and the \SP{}
  regression test suite.

  \paragraph{Knowledge}
  % What new facts were uncovered? If the
  % research was not results oriented, what new
  % capabilities are enabled by the work?
  Our main finding is that the \emph{gradual soundness}\/ that
  arises from a mix of concrete and transient types is an effective
  way to lower the maintenance cost of the concrete approach.
  On a more technical level, this paper contributes two artifacts:
  a model of \SP{} that passes all relevant tests from the \SP{} codebase
  and a performance evaluation of \SP{}.

  \paragraph{Grounding}
  % What argument, feasibility proof, artifacts,
  % or results and evaluation support this work?
  Our model of \SP{} is implemented in PLT Redex and tested against
  the \SP{} regression suite.
  This paper includes a small core of the model to convey the main ideas
  of the \SP{} approach and its soundness.
  Our performance claims are based on production experience in the Instagram
  web server.
  Thanks to \SP{}, global CPU usage has improved by almost 4\% within a year.

  \paragraph{Importance}
  % Why does this work matter?
  \SP{} is the first sound gradual language whose piece-meal application
  to a realistic codebase has consistently improved performance.
  %% Prior work on Nom and Dart 2 showed that concrete types are promising.
  Other language designers may wish to replicate its approach,
  especially those who maintain unsound type checkers for untyped languages
  such as JavaScript.

\end{abstract}


\section{Typing for Performance}
\label{s:intro}

Gradual typing has attracted significant interest as a solution to
the impasse between static and dynamic typing.
The premise is simple: let programmers introduce types in part of a
codebase and while leaving the rest untyped.
Run-time checks can in principle enforce the assumptions that
typed code makes about untyped components, thereby ensuring that
the types are sound no matter how the untyped code behaves.

Unfortunately, the high run-time cost of sound types has split
the gradual typing community.
Industry teams have developed innovative type systems that accommodate
untyped designs, but are unsound [CITE].
These systems intentionally check nothing at run-time when untyped values enter
typed code.
Academic teams have primarily focused on the theory of sound
gradual types, formulating correctness properties and studying ever-more-descriptive types [CITE].
A few academics have studied the cost of run-time checks
in detail [CITE] and proposed implementation methods [CITE],
compiler technology [CITE],
and even weakened semantics [CITE], but these efforts have not yet
decisively closed the performance gap.
The most promising attempt is the \emph{concrete} semantics
for gradual types [CITE kafka nom etc], but its low performance
overhead stems from severe restrictions on untyped code.
%% In other words, concrete types impose low performance costs
%% but high migration costs.
%% ... you can have any color as long as it's black -h.ford
%% ... concrete expresses few programs, but runs them all nicely
Whether developers can accept these restrictions is unclear;
indeed, they may prefer a whole-sale migration over an awkward
gradual transition.\footnote{Successful migrations of untyped codebases
to a typed language are rare, but not unheard of.
Twitter ported its server-side code from Ruby to Scala
and Dropbox moved its core sync engine from Python mypy to Rust: see
\shorturl{http://www.}{artima.com/scalazine/articles/twitter\_on\_scala.html} and
\shorturl{https://}{dropbox.tech/infrastructure/rewriting-the-heart-of-our-sync-engine}.}

In short, academic researchers are working to close the performance gap
without overly restricting the promise of gradual typing.
Industry researchers are sidestepping the problem with unsound types---for the most part.

This paper reports on a remarkable exception to the rule among industry-made gradual type systems.
The \SP{} team at Instagram has developed a \emph{sound} type system for a subset of
Python along with a runtime system that uses soundness to drive optimizations.
The language design is a variation of concrete types that eases its restrictions.
Instead of asking programmers to migrate from untyped code to sound concrete types
in one leap, \SP{} offers an intermediate step via shallow types that enforce
only the top-level shape of values.
Programmers can begin with shallow claims and gradually dial up soundness.
On a suite of benchmarks and production modules, Static Python out-performs untyped
Python across the board.


\paragraph*{Contributions}

\begin{itemize}
  \item
    Evidence that gradual soundness delivers Python-level performance at a low migration cost
    and faster performance as programmers gradually incorporate sound types.
    \SP{} can be applied to a codebase with no refactoring and marginal performance overhead.
    After refactoring to sound types, \SP{} performs well on a microbenchmark
    suite and in production.
  \item
    A formal description of the \SP{} core language and an analysis of its soundness
    and optimizations.
    Soundness is gradual in the sense that some types are fully sound and others validate
    only top-level shapes.
  \item
    Discussions of the expressiveness limitations in \SP{} relative to
    idealized gradual type systems, and of the programming discipline that Instagram
    follows in their gradually-sound codebase.
\end{itemize}


\paragraph*{Significance}

We have written this paper with two audiences in mind.
First, we want to encourage system-builders to reproduce the
\SP{} language design.
In particular, the maintainers of optionally-typed languages
may find that adding transient and concrete types is a low-overhead
way to turn types into reliable claims.
Second, we want to lend focus to researchers.
Some of the restrictions that \SP{} adopts may be useful to
ground theoretical work.
Other restrictions might be lifted by future research.


\section{\SP{} and the Cinder JIT}
\label{s:tour}
%% purpose = SP looks like Pyre, adds soundness to certain types

% {Language Pipeline}
% \begin{enumerate}
%   \item Pyre as an optional, but recommended pre-check. (Not necessary for the model.)
%   \item SP type checker
%   \item Custom bytecode, Cinder JIT
% \end{enumerate}

\SP{} is a type checker and bytecode compiler.
It validates programs written in ordinary Python syntax
and generates type-specific instructions for the Cinder runtime.
The type system can express common Python idioms and is guaranteed
sound through run-time checks, which in turn enable optimizations.
The type system also includes a dynamic type as an escape hatch to
untyped behavior.
An unannotated variable behaves exactly as it would in Python.

Cinder is an extension of CPython 3.8 that adds a method-based
JIT compiler, virtual method tables, and several bytecode instructions
to directly express type checks and type-based optimizations.
These enhancements take full advantage of \SP{} type information.
They are built on top of CPython so that untyped code runs on
the platform.

Using \SP{} and Cinder is as easy as installing a new version
of CPython.
The main executable compiles programs to bytecode on the fly,
same as CPython, allowing standard developer tools to work.
By contrast, the only effective way to get type-directed optimizations
without changing CPython is to use C extension modules,
which introduce an extra compilation step and get in the way
of tooling~(\cref{s:related}).

\begin{figure}
  %% TODO replace with a real program
%  \begin{minipage}[t]{0.5\columnwidth}
  \begin{verbatim}
    from __static__ import PyDict

    def f(x: PyDict[str, int]):
      return x["A"]

    f({"A": 1}) # ==> 1
  \end{verbatim}
%  \end{minipage}\begin{minipage}[t]{0.5\columnwidth}
%  \begin{verbatim}
%    from __static__ import PyDict
%
%    def f(x: PyDict[str, int]):
%      check_args(x, PyDict)
%      return cast(x["A"], int)
%
%    invoke_function(f, {"A": 1}) # ==> 1
%  \end{verbatim}
%  %  ....
%  %  CHECK_ARGS
%  %  ....
%  %  INVOKE_FUNCTION
%  \end{minipage}
%  \begin{verbatim}
%    from __static__ import CheckedDict
%
%    def f(x: CheckedDict[str, int]):
%      return x["A"]
%
%    f(CheckedDict({"A": 1}))
%  \end{verbatim}
  \caption{A first \SP{} program}
  \label{fig:sp-example}
\end{figure}

\Cref{fig:sp-example} presents a first example program.
It defines a function \code{f} and calls it from typed code.
The syntax is normal Python with type annotations.
Only the import statement makes special use of \SP{};
it imports a type \code{PyDict} that describes Python dictionaries.

Although this program is typed, a different untyped module is free
to import the function \code{f} and invoke it with any sort of
argument.
For this reason, the compiled version of \cref{fig:sp-example} must
include a few run-time casts:
\begin{itemize}
  \item
    The function \code{f} must check that its arguments match the \code{PyDict} domain annotation.
    \SP{} inserts a check that accepts any Python dictionary.
  \item
    Because the domain check does not validate the elements of an incoming dictionary,
    the dict access (\code{x["A"]}) must check that its result matches the function codomain.
\end{itemize}
These checks ensure a \emph{shape-level} notion of type soundness~(\cref{s:model}).
In short: if an expression has type \code{T} and reduces to a value, then the value
matches the top-level constructor, or shape, of the type.
The shape for a Python dictionary is merely \code{dict}.
Other types have deeper shapes; for example, \SP{} includes a \code{ChkDict}
type that predicts the keys and values in a special kind of dictionary.

Thanks to these checks, \SP{} can leverage type soundness to generate efficient code.
Because the call to \code{f} in \cref{fig:sp-example} appears in typed code,
there is no need to check that it sends type-correct inputs.
Thus, the compiled call is optimized to use a Cinder bytecode instruction
that skips the domain check and immediately enters the function body.

The checks and optimizations in this example illustrate the general balancing act
of \SP{}.
Type soundness requires run-time checks, but also enables optimizations.
The gamble is that the optizations help more that the checks hurt.


\subsection{Type System Highlights}

The \SP{} type system is a unique synthesis of ideas from the gradual typing literature
and prior work on types for Python.
Nom~\cite{mt-oopsla-2017,mt-oopsla-2021} and PEP 484~[CITE] are two notable sources.
Relative to these, the \SP{} takes some interesting turns
because of the engineering context at Instagram.
The following contextual points are important to bear in mind as we present
notable aspects of the type system:
\begin{itemize}
  \item
    Performance is the bottom line.
    Unless \SP{} helps production code run faster, the team will be disbanded
    and reallocated.
    %% 2021-12-14: too extreme? and what about soundness?
  \item
    %% Q. why is the python so nominal? style guide? java background?
    The codebase depends heavily on first-order functions and objects in
    performance-critical code.
    Higher-order code is fairly common, but rarely appears on a critical path.
  \item
    Prior to investing in \SP{}, Instagram used Cython to compile
    performance-critical code to C extension modules.
    Cython performed well, but mixing pure Python with a few compiled modules
    made for an awkward developer experience.
    \SP{} aims to match the Python workflow.
  \item
    The Instagram codebase is already typed.
    Developers use Pyre [CITE], an optional type checker for Python,
    to write type annotations and to drive IDE tools (e.g., autocompletion).
\end{itemize}



\subsubsection{Type Dynamic}
\label{s:type-dynamic}

%% 2021-12-14:
%% - anything to say about Any being a "meta" type in Python typing module?
%% - 3 classes of code ... how does dynamic differ from untyped?

Like most gradual languages, \SP{} includes a dynamic type
that allows untyped expressions within a statically-typed context.
Whenever an expression or variable lacks a type annotation, \SP{} uses the
dynamic type as a default and skips most (but not all!) compile-time checks.
Every untyped Python program is thus a well-formed \SP{} program.
Furthermore, programmers can omit the annotations for specific
function arguments without losing the benefits of other type checks.
Freedom to omit annotations helps programmers convert modules to \SP{}
with little initial refactoring.

In addition to serving as a default, the dynamic type also replaces any undefined types.
For example, suppose that the type \code{X} is undefined in \SP{} and that a
program contains the annotation \code{ChkDict[int, X]}, which describes a
dictionary with integer keys and \code{X}-typed values.
\SP{} interprets this annotation as \code{ChkDict[int, dynamic]} and allows any sort
of values inside the dictionary at runtime.

At first glance, this behavior might seem odd: why not reject undefined types with an error?
The reason is to reduce friction with the Pyre annotations that are already
widely-used at Instagram.
Pyre is a mature static type system that can check more types than \SP{} knows how to enforce
efficiently, e.g., the type \code{Union[t1, ..., tn]} of arbitrary-width unions~(\cref{s:idiomatic-types}).
By replacing such types with dynamic, \SP{} can accept Pyre code that it does not yet fully understand.

%% intro sentence
The dynamic type is also different than the flexible dynamic type provided
by true gradual languages~\cite{svcb-snapl-2015}.
Replacing part of a type with dynamic can lead to both compile-time errors
and run-time errors.
In other words, \SP{} satisfies neither the static nor the dynamic gradual guarantee
for a standard type precision relation.
%% \footnote{We
%% assume a standard type precision relation. Of course, one could argue that these programs
%% do not break the gradual guarantees for a type precision relation that is tailored to \SP{}.}
%%   %% tailored = describes exactly the migrations that SP allows
\Cref{fig:gg-failure} presents two examples, one for each kind of failure:
%% \footnote{In addition, C types~(\cref{s:ctypes}) are incompatible with type dynamic.}
\begin{itemize}
  \item
    \Cref{f:gg-failure-stat} presents a fully-typed class and a partially-typed subclass.
    The subclass definition raises a compile-time error because it attempts to override
    the typed \code{m1} method with another method that returns the dynamic type.
  \item
    \Cref{f:gg-failure-dyn} presents a variant of \cref{fig:sp-example} that
    uses the type \code{ChkDict} for concrete-typed dictionaries (\cref{s:checked-type}).
    It sends a dictionary with integer values to a function that expects
    dictionaries with dynamic values.
    At runtime, the function rejects this argument because its type is not an
    exact match.
\end{itemize}
These behaviors are a consequence of \SP{} being driven by the needs of an
existing codebase.
The literature on gradual types has served only as a guide, not a mandate.

\begin{figure}
  \begin{subfigure}[t]{0.5\columnwidth}
  \begin{verbatim}
    class A:
      def m1(self)->int:
        return 0

    class B(A):
      def m1(self):
        return 0
    # Error: type dynamic does not match int
  \end{verbatim}
    \caption{Removing a type in \code{B} breaks the static gradual guarantee}
    \label{f:gg-failure-stat}
  \end{subfigure}
  ~
  \begin{subfigure}[t]{0.5\columnwidth}
  \begin{verbatim}
    from __static__ import ChkDict

    def f(x: ChkDict[str, dyn]):
      return x["A"]

    d = ChkDict[str, int]({"A": 1})
    f(d)
    # Error: f expected ChkDict[str, dyn]
  \end{verbatim}
    \caption{Removing part of the type for \code{x} breaks the dynamic gradual guarantee}
    \label{f:gg-failure-dyn}
  \end{subfigure}
  \caption{\SP{} values performance over the gradual guarantees.}
  \label{fig:gg-failure}
\end{figure}


\subsubsection{Concrete Types and Shallow Types}
\label{s:checked-type}

Every \SP{} type corresponds to a simple run-time check.
When an unknown value reaches a boundary to typed code at run-time,
\SP{} uses these checks to quickly decide whether or not the value
matches the type.\footnote{In other words, \SP{} provides \emph{immediate accountability}~\cite{mt-oopsla-2017}.}
Unlike structural gradual type systems, \SP{} does not traverse
incoming values nor does it create wrappers to enforce behavior.

These checks try to faithfully enforce the full type, but some are incomplete.
We call the incomplete ones \emph{shallow} types; examples follow.

First off, for a basic nominally-typed language (think Java 1.4, before
generics), simple and full checks are easy to implement.
Every type has a name and every value can carry a tag that corresponds to the
name of its type.

Parameterized types (generics) are more difficult to fully enforce without
changing the language.
Consider a list datatype \code{List[T]} that is parameterized by the
e type of its elements.
If a function expects lists of integers (\code{List[int]}), then a simple check
for lists is not strong enough to decide whether an incoming value matches the
type~(\cref{f:list-boundary}).
A deeper check is needed to validate the list elements.
But, the default \code{List} type cannot support such a check because untyped
code is free to create lists.

The \SP{} solution is to provide two versions of every parameterized type,
both of which support efficient run-time checks.\footnote{Currently, only a handful
of built-in data structures provide shallow and concrete versions. User-defined
classes will soon follow this approach.}
One version is shallow.
The other is \emph{concrete}: complete, but new.
Consider \code{List[T]} as an example:
\begin{enumerate}
  \item
    \emph{Shallow type \code{List}}.
    The default type \code{List[T]} gets enforced with a simple check for lists that ignores
    the elements.
    Consequently, every static type like \code{List[int]} is merely a promise of \code{List}
    values at run-time.
  \item
    \emph{Concrete type \code{ChkList[T]}}.
    \SP{} introduces a new data structure and parameterized type \code{ChkList[T]}
    for concrete types.
    The data structure implements the list API and comes with a checked constructor that
    makes it impossible to create a \code{ChkList[int]} with non-integer elements;
    \cref{s:chkdict-impl} discusses the implementation further.
\end{enumerate}
%
These options let programmers decide whether to change their code to benefit from
fully-sound types, or leave it as-is for a lower payoff.


\begin{figure}[t]
  How to enforce type \code{List[int]} simply?
  \begin{itemize}
    \item Checking for \code{List} is simple, but loose. It accepts \code{List[str]} and heterogeneous lists etc.
    \item Can't check for \code{List[int]} by itself, the datatype does not support that.
    \item Checking for \code{ChkList[int]} is simple, but needs buy-in from users.
    \item Show venn diagram of the options?
  \end{itemize}
  \caption{FILL illustrate list boundary and checks}
  \label{f:list-boundary}
\end{figure}

Often, the shallow types are more attractive because concrete types impose
a ripple effect throughout the codebase.
If one type changes to concrete, then all data constructors that reach this type need
to change \emph{and then} all their clients need to use the concrete type as well.
\Cref{s:concrete-migration} discusses this migration cost of concrete types further.


\subsubsection{Gradual Class Hierarchies}
\label{s:inheritance}

One important feature of \SP{} is that class hierarchies can
mix typed and untyped code.
An untyped class may inherit from a typed one and vice-versa.
The point of this feature is to let programmers add types to a single class
independently of its ancestors and children.

% st-ecoop-2007 has no inheritance, object is collection of members simple (Abadi--Cardelli)

Gradual class hierarchies are rarely studied in the literature, especially
for a language where truly untyped classes can enter the mix.\footnote{Two
languages that provide separate hierarchies for untyped and (gradually) typed
classes are Thorn~\cite{wzlov-popl-2010} and SafeTS~\cite{rsfbv-popl-2015}.}
The closest related work, for Nom~\cite{mt-oopsla-2017}, is much more flexible.
\SP{} explores a simpler point in the design space, starting with
a few restrictions on types and inheritance:

\begin{enumerate}
  \item
    To benefit from types, classes must be declared on the module top level
    and may have at most one parent.
    Nested class declarations, first-class classes, and classes with
    multiple parents default to un-optimized Python behavior~(\cref{s:impl}).

  \item
    Methods cannot be overloaded.
    This restriction comes from Python.

  \item
    Methods and fields may be overridden in arbitrary ways by untyped code.
    In typed code, however, overrides must be compatible subtypes.
    For example, a method that returns a number cannot be overridden by a method
    that returns the dynamic type~(example: \cref{f:gg-failure-stat}).

    % In fact, \SP{} compiles fields using Python slots
    % declarations (\code{\_\_slots\_\_}).
    %
    % NOTE __ (dunder) methods may be overridden e.g. __getattribute__,
    % but the normal field access syntax skips any overrides (o.f)

\end{enumerate}
%
With this context in mind, every class member is either \emph{reliably} typed or untyped.
In particular, a typed member cannot be overridden by a less-precise one that uses
type dynamic.
\SP{} can therefore optimize dispatch from typed callers to typed methods
and use checked dispatch for other combinations.
One extra step arises when an untyped class overrides a typed method.
In this case, \SP{} creates a wrapper around the overriding method to check
that it computes type-correct results.
% Because these wrappers perform a simple first-order check, they
% are supported by an efficiently implementation that cooperates with
% \SP{}
The wrappers are handled efficiently by \SP{}'s vtables~(\cref{s:vtable}).


\subsubsection{Tailored Types}
\label{s:idiomatic-types}

\SP{} is selective about which types to support and which to omit.
In general, supported types are widely-used and come with an efficient
implementation.
Other widely-used types are deferred to Pyre for static checks until
the day when \SP{} adds support.\footnote{At present, the \SP{} team
has no plans to support all Pyre types. The top priority is to implement
core types efficiently.}

The core supported types describe basic data (integers, booleans, strings),
data structures (lists, dicts, promises),
and nominal classes.
Additional ``C types'' enable aggressive compilation of primitive
values~(\cref{s:ctypes}).
Union types are well-supported statically and narrow down in accordance
with type tests (a form of occurrence typing~\cite{tf-icfp-2010,gsk-esop-2011}),
but hardly supported at run-time.
Only binary unions of a type and false get enforced with a run-time check
(\code{Union[T, False]}, or \code{Optional[t0]}).

Three unsupported types bear special mention.
There are no first-class class or object types, as noted in \cref{s:inheritance}.
There are also no types for first-class functions (callables).
Pyre can check these types instead, to point out clear logical flaws.
Finally, \SP{} does not support recursive types due to low demand.
Neither Pyre nor mypy have recursive types either.
%% demand seems low ... baffling
%% mypy = https://github.com/python/mypy/issues/731
%% nothing in pep 484 = https://www.python.org/dev/peps/pep-0484/


\subsection{Runtime System Highlights}
%% Non-Highlights:
%% - shadow frames = JIT feature, lite array to track Python call stack
%% - strict modules ... avoids toplevel function wrapper

Cinder, the \SP{} runtime system, extends the standard Python runtime in
several ways.
Some of these ensure the integrity of types.
Others use type soundness to generate efficient code.


\subsubsection{Bytecode Instructions}

Cinder is a bytecode compiler that extends the Python instruction set.
All the standard Python instructions work similarly to Python 3.8;
in other words, an untyped Python program has the same semantics in
Cinder as in the standard interpreter.
The added instructions help either to express runtime checks or to
quickly perform a statically-determined action.

The two main instructions that express run-time checks are \code{CAST}
and \code{CHECK\_ARGS}.
The former checks a value against a type.
The latter is a special cast for functions and methods;
it appears at the top of every function and checks that the
actual parameters match the types of the formal parameters.

A simple optimizing instruction is \code{FAST\_LEN}, which expects
a built-in value\footnote{Because of subtyping, it does not suffice to check
the type. All Python lists support \code{FAST\_LEN} but some subclasses
of the Python list type may not.}
and quickly computes its length.
Another is \code{LOAD\_FIELD}, which scans a fixed offset within an object.
By contrast, the standard Python instruction for loading a field needs to
search a dictionary~(\code{LOAD\_ATTR}).

In addition to speeding code up, the \SP{} compiler takes care
to avoid slowing code down.
It does so by avoiding casts and run-time checks that are certain to succeed.
For example, calls from a typed context to a typed function are statically
checked for compatibility.
There is no need to run \code{CHECK\_ARGS} on typed inputs, so the bytecode
compiler inserts a special call instruction to skip past the check.



\subsubsection{Virtual Method Tables}
\label{s:vtable}

Cinder adds virtual method tables (vtables) to typed classes.
These tables help to speed up method dispatch relative to Python's
dynamic lookup.

Specifically, calls to static methods that appear in statically-typed
code use the vtable to find an address for the method.
If the method is part of a final class, then the call is further optimized
to a direct function-call jump.
JIT compilation can also upgrade vtable lookups to function calls.

%% related bytecodes: INVOKE_METHOD INVOKE_FUNCTION
%%  JIT can upgrade I_METH to I_FUN
%%  final classes get I_FUN
%% implementation: built on Python vectorcalls, so it's not totally new
%% beware: with vtables, method resolution is different than Python b/c args. get
%%   resolved before the receiver (A.m(B) goes "A->B" in Py. and "B->A" in SP)
%%
%% > This difference in behavior isn’t so much desired as just a consequence of making
%% > `INVOKE_METHOD` optimizable. With a normal dynamic `CALL_FUNCTION`, first
%% > the callable is placed on the stack, then the arguments, then there is a
%% > `CALL_FUNCTION` (with number of args in oparg) to perform the call. This
%% > means that first the callable is resolved, then the arguments. But with
%% > `INVOKE_METHOD` we want to resolve the callable as part of the invoke
%% > itself, since this gives us opportunity to inline-cache the target of the
%% > call instead of always having to call something dynamic and unknown that’s
%% > on the stack. So that necessarily implies that first the arguments are
%% > resolved and placed on the stack, then the callable is resolved as part of
%% > the `INVOKE_METHOD`. -Carl


\subsubsection{Checked Data Structures}
\label{s:chkdict-impl}

As mentioned above~(\cref{s:checked-type}), the concrete versions of built-in data structures
come with both a type and an implementation.
The implementation provides the same interface as the built-in,
but uses the type to reject some uses.

For example, the type \code{ChkDict[K, V]} describes a concrete dictionary
with keys of type \code{K} and values of type \code{V}.
The implementation has three main components:
\begin{itemize}
  \item
    A constructor that uses a type and a Python dictionary
    to initialize a checked dictionary.
    The constructor ensures that all values of type \code{ChkDict[K, V]}
    begin with well-typed elements.
  \item
    Guarded update functions.
    Every operation that mutates or extends a checked dictionary must
    validate untyped arguments.
  \item
    A type tag for boundary checks.
    When a checked dictionary enters typed code from an untyped context,
    the runtime checks its key and value types for an exact match.
    For example, a value of type \code{ChkDict[K, V]} matches the type
    \code{ChkDict[str, dynamic]} only if \code{K} is type \code{str}
    and \code{V} is dynamic.
\end{itemize}
%
In general, other checked datatypes have the same three components:
a constructor, checked update functions, and a tag.


\subsubsection{Unboxed Primitive}
\label{s:ctypes}

For performance-critical applications, \SP{} includes a \emph{distinct} set of primitive types
that describe booleans and sized numbers, e.g., \code{int64}, \code{uint64}, \code{double}.
Cinder implements these types with unboxed C values, which are much simpler and cheaper
than their Python counterparts.
\SP{} also includes two special datatypes, \code{Array} and \code{Vector}, that store primitives efficiently.
These are not themselves primitive.

Primitives are carefully limited by the type system.
Neither a module-level nor a closure-level variable may have a primitive
type---because untyped code can mutate such variables.
Primitive types are incompatible with the dynamic type,
and there are no implicit upcasts from primitives
to a matching Python type.
Even a conjunction disallows mixing; for example, the \code{and} operator
requires either two Python booleans or two primitive booleans.
The only way for Python values and primitive values to interact
is through dedicated conversion functions.
Cinder handles conversions at the boundaries between \SP{} code
and untyped code to avoid a cascade of modify-then-run refactorings, but nowhere else.
Within typed code, programmers must satisfy the type checker with
appropriate conversions.

% For now, programmers have to write and manage primitive types.
% In the future, a preprocessor might convert Python arithmetic to primitive arithmetic.

% https://github.com/facebookincubator/cinder/issues/52



\section{Model}
\label{s:model}
%% purpose = types, checks, and optimizations can be formalized and analyzed

%% NOTE
%% - remark: model gives errors of the same kind in SP, but not always the same
%%   message, after all its not our goal to reproduce SP exactly

\subsection{Goals and Limitations}

Our model of \SP{} includes the key aspects of its types,
statements, and values.
The model has two main goals:
illustrate the boundaries where typed and untyped code can mix,
and show how to soundly protect these boundaries.
Compared to other gradual languages, these boundaries are quite restrictive---which
partly explains \SP{} performance~(\cref{s:eval}).
Indeed, the model is nearly a subset of the model for Nom~\cite{mt-oopsla-2021},
hence we focus on explaining the gaps and omit formal proofs.

The model intentionally does not cover all of Python.
Some aspects of \SP{} are left out because they are straightforward to
handle soundly (FILL examples ... while loop?).
Omitting these lets us focus on the difficult corners.
Other Python features are left out because their \SP{} semantics is identical
to Python.
These include \code{eval}, first-class classes, multiple inheritance, and module-level cells.
\SP{} does not rely on types for these features to guide program transformations;
see \cref{s:impl} for further discussion.


\subsection{Surface Language}

\begin{figure}[t]
  %% ported types from redex model
  \begin{langarray}
    \sptype & \defeq &
      \sptdyn \langmid
      \sptnone \langmid
      \sptclass \langmid
      \sptinstanceof{\sptclass} \langmid
      \sptfun{\sptype}{\sptype} \langmid
      \sptunion{\sptclass}{\sptclass}
  \\
    \sptclass & \defeq &
      \sptint \langmid
      \sptfloat \langmid
      \sptobject \langmid
      \sptpydict{\sptclass}{\sptclass} \langmid
      \sptchkdict{\sptclass}{\sptclass} \langmid
      \mbox{(user defined class)}
  \end{langarray}

  \begin{center}\parbox{0.8\columnwidth}{
    Abbreviation: $\sptoptional{\sptclass} \defeq \sptunion{\sptclass}{\sptnone}$

    EXCEPT THAT $\sptoptional{\sptclass}$ may be a generic parameter just like any other class $\sptclass$

    Function types cannot expect or return other function types.
  }\end{center}

  \caption{Surface Types}
  \label{f:surface-types}
\end{figure}


\subsection{Evaluation Language, Optimizations}

\begin{figure}[t]
  \(
    \mftypeF{\sptype_0}
    \mfeq
    \left\{\begin{array}{ll}
      \sptrawpydict & \mbox{if $\sptype_0 = \sptpydict{\sptclass}{\sptclass}$}
    \\
      \sptype_0 & \mbox{otherwise}
    \end{array}\right.
  \)

  \caption{Surface Types to Evaluation Types}
  \label{f:surface-to-eval-types}
\end{figure}


\subsection{Properties}

\begin{theorem}[Type Soundness]
  If\ \(~\vdash \spexpr_0 : \sptype_0\)
  then one of the following holds:
  \begin{itemize}
    \item
      \(\spexpr_0 \sprred \spvalue_0
        \mbox{ and }
        \vdash \spvalue_0 : \mftypeF{\sptype_0}
      \)
    \item
      \(\spexpr_0\) diverges
    \item
      \(\spexpr_0 \sprred \sperror\)
  \end{itemize}
\end{theorem}

\begin{theorem}[Optimization Soundness]
  If\ \(~\vdash \spexpr_0 : \mftypeF{\sptype_0}\)
  then\ \(~\vdash \mfopt{\spexpr_0} : \mftypeF{\sptype_0}\)
\end{theorem}

%\begin{theorem}[Optimization Effectiveness]
%  FILL how do we know optimizations are useful rather than trivial?
%  %% - length of eval(e) vs. eval(opt(e)) might be longer (good) or shorter (bad)
%  %%   for general heuristic opts.
%  %% - is [opt(e) != e] true for interesting programs?
%\end{theorem}


\subsection{Bug Reports}

While formalizing Static Python, we submitted N bug reports to the language developers.
The developers acknowledged M of these bugs as issues to fix.

\begin{center}
  %% most filed by KC, a few by Ben
  \shorturl{https://}{github.com/facebookincubator/cinder/issues/created\_by/LuKC1024}
\end{center}


\section{Scaling to Python}
\label{s:impl}

%% TODO discuss optimizations here, not in sec 2

%% TODO SP side channels:
%% ?? eval,
%% the locals and globals dicts (the latter can be accessed through frame objects at the moment),
%% and mutable closure cells.

%% TODO built-in vs. user defined ... 
%% Carl: I don't think this is quite true the way it's phrased here? in general
%%   for SP classes we wrap non-static subclass override methods at runtime (in our
%%   vtable implementation) to enforce correct return type, so that we don't need
%%   exact types, we can trust that Liskov is not broken.
%%     The cases where we tend to be limited to exact types is in optimizing
%%   operations on builtin types, where they aren't really static types and
%%   methods called on them aren't going through SP vtables, so we don't have
%%   the vtable wrappers to enforce LSP, we just know the behavior of the exact
%%   builtin type

%% TODO wherever we discuss optimizations, also talk about de-slowdowns
%% Carl: not sure where this belongs exactly, but we go to a lot of work in the
%%   compiler to intelligently minimize runtime checks by only inserting them when
%%   the source value is of dynamic type (this includes also skipping CHECK_ARGS if
%%   the function was statically invoked by another static function and thus we
%%   know the compiler checked argument types)


[FILL]

Purpose: explain significant gaps between the model and the implementation.
E.g. what would the TypeScript team need to know before using our model
to add soundness?

\subsection{Dynamic Python Features}

\SP{} does not ascribe types to the following Python features.
These are not covered in our model because the implementation simply
assigns the dynamic type and lets the runtime treat them as untyped
Python code.
For each, we claim that the dynamic type is a reasonable choice;
accurate static types would be difficult to maintain.


\paragraph{First-Class Classes}

\SP{} does not attempt to type first-class classes: partly because they have
yet to appear in performance-critical code at Instagram and partly because it
is unclear how to incorporate them into the nominal type system.
The straightforward but restrictive approach is to force code that uses a
first-class class to expect subtypes of a particular named static class.
Flatt et al.~\cite{fkf-popl-1998} propose a more-flexible approach, %(specifically for mixins)
but it requires a second layer of \emph{interface types} atop the nominal hierarchy.
MonNom~\cite{mt-oopsla-2021} uses interfaces in a similar way to accommodate
structural objects.
Adding an interface layer to \SP{} is an open question.

% in particular , Python's multiple inheritance would complicate the mixin story.
% Classic mixins rely on structural types~\cite{bc-oopsla-1990}.

%Notes on first-class classes being untyped:
%- mixin-based code tends to structrural types
%- nominality overly restrictive, get forced into <: hierarchy
%- but don't have NO IDEA for wat to do
%  + classes and mixins paper shows one idea,
%    ... need complicated mixin study??? (many sub objects)
%    built new type system to be mixin-aware, layered atop java
%    unsure if such extension works for SP
%    furthermore, class-and-mixins depends on Java single inheritance
%  + bracha cook mixin pattern
%  + tate muehlboeck structural object + interfaces


\paragraph{Multiple Inheritance}

%% https://docs.python.org/3/reference/datamodel.html
%% TODO check Dino email, confirm with C&D that layout conflict is unrelated to vtables

Python allows classes to inherit from a list of parents.
When resolving a method call to such a class, Python
dynamically traverses the parent list in a fixed order
seeking a first match.

Due to the dynamic method resolution order (MRO),
\SP{} does not track types for classes with multiple parents.
Method calls to these classes execute the same way as
in Python, with no type-directed optimizations to speed up dispatch.


\paragraph{Dynamic Execution}
%% TODO is eval a side channel, or safe?
%% TODO check that eval/exec args really are unoptimized / sound etc.
Results computed by calls to \code{eval} and \code{exec}
have the dynamic type.
Their inputs run without being rewritten
by the optimizer.

Studies of JavaScript and R have shown that many uses of dynamic execution
can be removed through simple adjustments~\cite{rhbv-ecoop-2011,gdkkv-oopsla-2021,mrmv-esop-2012}.
Assuming these findings carry over to Python, we recommend either similar
adjustments or the introduction of semantically-descriptive replacements
over attempting to type eval.


\paragraph{Module-Level Variables}

Any Python module can read and write to the module-level variables of another module.
When compiling a module, \SP{} therefore assumes that its module-level variables
may be modified by untyped code and assigns the dynamic type.

Cinder offers \emph{strict modules} as an alternative to the Python
semantics.\footnote{https://instagram-engineering.com/python-at-scale-strict-modules-c0bb9245c834}
If a programmer chooses to declare a module as strict, then its module-level varibles
are immutable and thus typeable.

Another potential solution is for the Cinder runtime to check that writes to module-level variables
preserve their types.
There are two downsides to this idea:
it will add some performance overhead,
and it will force developers to rewrite untyped code in order to fix any errors that arise.
%% Because of the latter concern, type dynamic is a very reasonable default.


\section{Production Experience}
\label{s:eval}
%% 2021-12-15: C&D may have an SP off/on switch soon to measure totals

% "The workload for those rough percentage numbers is “Instagram web server
%  production.” We have pretty extensive production profiling that lets us
%  identify CPU savings with good granularity when a change lands in prod, and the
%  observed CPU savings for a variety of staticification changes we’ve landed over
%  the last half sum up to 2% of total IG prod CPU usage." --Carl

\begin{table}
  \caption{Overview: \SP{} in production}
  \label{t:prod-stat}
  \begin{tabular}{l@{~~}ll@{~~}l}
    8     & months in production & 3.7\% & global CPU improvement \\
    530   & modules converted  &  0 & performance regressions
    %% TODO 530 / ???? how much of codebase?
  \end{tabular}
\end{table}

The Instagram web server has been running \SP{} in production since April 2021.
Overall, the results are very encouraging.
Instagram's internal profiling tools, which continuously monitor
performance, attribute a 3.7\% improvement in global CPU to \SP{} conversions.
\cref{t:prod-stat} reports a few other production statistics.
Over 500 modules have been converted thus far.
None of the converted modules have gotten slower because of \SP{}


\subsection{The Migration Path}

\SP{} first entered the Instagram web server as a replacement for Cython,
which Instagram had been using to speed up critical modules.
Cython performed well, but its partial adoption led to an awkward workflow
because unlike standard Python, Cython is a compiled language.
Replacing these modules with \SP{} let developers return to a conventional
Python workflow.
\SP{} (combined with Cinder) did not slow down any of these
performance-critical modules, and even sped a few up.
The net improvement was a 0.7\% reduction in global CPU usage.

Later \SP{} migrations have been led by profiling to find frequently-executed code.
The goal of these opportunistic migrations was to test whether \SP{} could
improve typical modules without slowing down their neighbors.
As a point of comparison, Typed Racket can improve individual Racket
modules but the type checks that it requires on module boundaries
can lead to huge slowdowns~\cite{tfgnvf-popl-2016,gtnffvf-jfp-2019}.
\SP{} does not appear to suffer in the same way.

During the first half of 2021, the \SP{} team identified critical
modules and proposed types to the maintainers of these modules.
Often, the types came with small code changes.
The accepted types and changes resulted in a 1\% improvement
in global CPU usage.
During the second half of 2021, the \SP{} team applied the same
process at a larger scale by incorporating a tool that drafts
initial type annotations.
These changes resulted in a 2\% global CPU improvement.

As of December 2021, the \SP{} team has converted 530 modules.
Most of these came from the annotation tool (400); the rest
are from hand conversions.
In a typical week, the team adds types to four additional modules.
These modules have seen speedups ranging from 0\% to 25\% depending
on their nature.
Regressions have not been an issue.
The only cause for alarm is when a module gets only a small improvement
without code changes.
%% - rough measure: 0 to 25% per module
%%   ... but depends on nature of module
%%   ... doesn't measure the cooperative effect of static-to-static cross-module calls


\subsection{Analyzing Code Changes}

The fact that the \SP{} team has been changing code as well as types
during its migrations is potentially troubling.
It could be that the \SP{} approach to gradual typing only pays off
after significant modifications, or only for a restrictive style of programming.

To understand the code changes, an author affiliated with Instagram reviewed
approximately 30 patches that significantly improved performance.
In general, the patches contain relatively minor code changes.
The biggest changes are to testing code rather than production code.
Both these points are encouranging.
The following nine points describe common patterns:

\begin{enumerate}
  \item
   adjustments to tests to pass correct types instead of mock objects, as as
   not to fail type checks in SP code. This is an inherent and desired
   incompatibility; next half we plan to work on improving the Python mock
   framework to automatically create mocks of the correct types.
   %% - bg: lookup the dino email about mocks

 \item
   adjustments to mock assertions in tests about calls to adjust for the
   fact that SP currently converts all call arguments to be positional (we plan
   to fix this incompatibility by falling back to the original call arguments
   when we detect the target function has been patched.)
   %% - bg: ??? bit fuzzy about positional and others

 \item
   adjustments around class attributes vs instance attributes (Python allows
   this to be a bit fuzzy, where a class attribute can be a fallback default
   for an instance attribute if not set, but SP currently requires an attribute
   to be clearly one or the other, and we have more efficient access for
    instance attributes via \code{LOAD\_FIELD} that we don’t have for class attributes.)
   %% - related to github #37 ?

 \item
   convert @classmethod that don’t actually need the class to @staticmethod,
    allowing for emitting direct \code{INVOKE\_FUNCTION} instead of \code{INVOKE\_METHOD}

 \item
   extract special types that our compiler doesn’t yet support/understand
   (classes decorated with @dataclass or inheriting from `enum.Enum`) out of
   the module we are converting to static. We have work in progress on
   supporting some Enum types, and plan to add a @dataclass intrinsic soon.

 \item
   Removing the use of super-dynamic Python features like \code{\_\_setattr\_\_} that
   we don’t support. So far in the cases where we’ve done this it hasn’t
   required a major rewrite.
   %% - bg: more details pls ,,, sketch the rewrite

 \item
   Removing the use of keyword-only arguments (bare `*`) in function
   signatures, since we don’t yet support calling such functions. We plan to
   support this next half.

 \item
   Convert Python integers and bools used in very hot code paths into SP
   machine primitives.
   %% - bg: focus on block, convert, no problem?

 \item
   Occasionally converting a regular Python list or dict to a CheckedList or
   CheckedDict.
   %% - bg: how occasional? worried about power of the "gradual soundness" claim
\end{enumerate}

%% significant change: replaced `contextlib.ContextDecorator` with `__static__.ContextDecorator`
%%  removes an extra call layer
%%  helps with (timing [ context managers / decorators ])
%%
%% all of this is the low-hanging fruit, haven't tackled uses of metaclasses even though looks promising
%%  because the pay / payoff isn't yet attractive


\subsection{Developer Experience}

%% - pushback one time about removing MI
%% - otherwise, people happy with low-cost improvements

%% - pyre challenges?


\subsection{Microbenchmarks}
%% https://github.com/facebookincubator/cinder/tree/cinder/3.8/Tools/benchmarks

%% TODO jit vs nojit

%% 2021-12-23: TODO decide whether to ask for typed benchmarks to report ratios
%%  Carl: we could commit to typed 2--3 more, but pystone etc (?!) are notoriously bad

%% Somehow though, we ought to have public code available.

Prior to deploying \SP{} in production, the team used microbenchmarks to study performance.
These microbenchmarks are admittedly small and quite different than typical application code.
That said, their use gave the team a coarse idea of whether \SP{} was on track during development.
We include these microbenchmarks to offer reproducible performance numbers;
unlike the Instagram web server, the benchmark code is public.

\Cref{t:microbenchmark} reports current microbenchmark results.
Each row gives the ratio of two running times: fully-typed \SP{} code versus
unannotated \SP{} code.
A ratio between 0 and 1 means that performance improved thanks to the types.
[FILL] numbers.

\begin{table}[t]
  \caption{Microbenchmark Performance Ratios}
  \label{t:microbenchmark}
  %% show untyped Python time?
  \begin{tabular}{ll}
    Name               & Typed / Dynamic \\\midrule
    \bmname{deltablue} &             0\% \\
    \bmname{fannkuch}  &             0\% \\
    \bmname{nbody}     &             0\% \\
    \bmname{nqueens}   &             0\% \\
    \bmname{pystone}   &             0\% \\
    \bmname{richards}  &         0.125\% \\
  \end{tabular}
\end{table}


%% TODO conclusions? threats?



\section{Related Work}
\label{s:related}

Nom~\cite{mt-oopsla-2017} and MonNom~\cite{mt-oopsla-2021} are foundational.

Full Monty~\cite{pmmwplck-oopsla-2013} core calculus for Python language, foundational for us.

Grace nominal transient aint bad at all

Thorn~\cite{wnlov-popl-2010} and StrongScript~\cite{rzv-ecoop-2015} are related.

PyPy is another runtime for Python
Pycket is built on PyPy and improves both Typed Racket~\cite{bbst-oopsla-2017}
and Reticulated Python~\cite{vsc-dls-2019}.

Type systems for Python ...
mypy pyre pytype;
Reticulated;

Optimizing type systems for Python ...
Reticulated;
mypyc;
Developer experience is one of the main advantages of \SP{} over mypyc,
which implements type-directed optimizations for CPython
by compiling source code to C extension modules.



\section{Future Work}
\label{s:future}

%% Immediate future: fix adoption friction points
%% 2021-12-15: WHAT ARE THESE?

%% engineering: JIT profiling, instead of hand-requested JIT list
%% model: metaclasses

Adapt SP ideas to a new setting, test performance takeaways.

Improve SP with generic types, structural types (lambda), \ldots.

Use confined GT to relax ChkDict ... let programmers decide whether
the type should reject or convert untyped data.
Maybe a ChkDict function could compile to an "overloaded" version with
fast and slow paths for ChkDict vs normal dict.

Build an automatic migration tool for Checked data.

Build a static analysis that hoists transient annotations to an early, shared point.
Take care to give quality error messages.

Optimize Python integer operations (in addition to the ctypes).
Hard because syntax like \code{a + b} may be the result of either \code{a.\_\_add\_\_(b)}
or \code{b.\_\_radd\_\_(a)} depending on runtime types and behavior.


\section{Conclusion / Lessons / Design Principles}
\label{s:conclusion}

\subsection{Nominal, Checked Types}
\label{s:concrete-migration}

CheckedDict enables strong type checks and optimizations, but is painful to use.
It is painful even though ChkDict supports the full dict API
(any context that uses a Python dict can use a ChkDict without code changes).

The problem is that the ChkDict type rejects all Python values.
It accepts only ChkDict values, built through a special constructor
that installs a tag for type tests and guards writes.
Suppose that \code{f} is an untyped dict function.
As is, it can process ChkDict but gets no benefit from type checks nor from optimizations.
Adding a ChkDict domain type enables optimizations within \code{f} but raises a non-local
problem: all callers of \code{f} must be sure to create a ChkDict.
These ChkDicts must also be monomorphic to match whatever type \code{f} chose.
It can take many edits to get a program running again after adding a ChkDict type.

Lessons:
\begin{itemize}
  \item
    Nominal types are not compatible with structual values, such as Python values.
    Programmers are forced to edit old code to use such types ... unless the recent Nom work has a better idea~\cite{mt-oopsla-2021}
  \item
    Monomorphic nominal types are even worse.
    Editing old code to fit their rigid constraints may not be feasible.

\end{itemize}

Enabling checked types has a huge ripple effect.
The worst case is changing an annotation to a expect a checked data structure:
\begin{enumerate}
  \item all callers must create a checked value by invoking the right constructor, and
  \item all clients of those callers can no longer expect an unchecked type.
\end{enumerate}
Programmers have to trace the annotation back to value-creation points, and then
ensure that all uses of those values are compatible.


\subsection{Pyre Compatibility}

Many decisions in \SP{} are influenced by the widespread use of Pyre at Instagram.
\begin{itemize}
  \item
    To minimize changes needed to adapt Pyre-annotated programs
    to \SP{}, the syntax of \SP{} is compatible with Pyre.
    Pyre can run useful checks on every \SP{} program.
  \item
    Because Pyre is a mature type checker, the \SP{} team has taken a
    depth-first approach to development.
    The language implements a small set of sound types efficiently and ignores
    other types.
    Of course, programmers who use advanced Pyre types can still use Pyre to
    get compile-time feedback.
  \item
    The fact that \SP{} interprets unknown Pyre types as type dynamic changes
    users' expectations about what the dynamic type should mean.
    It is not necessarily a label for untyped Python code; dynamic code
    can be analyzed to catch static bugs.
    %% FILL what are the checks?
\end{itemize}


\subsection{Conclusion}

Sound types in Static Python give programmers a way to improve performance.
The change is not forced, not intrusive;
programmers can keep using unsound types when working toward a deadline.

Conjecture that soundness will find bugs too, and lead to more reliable products.
Too soon to say.


\subsection{Communication}

How did we communicate effectively?
Starting point was GT survey [CITE].
Moved forward with example programs, see emails and github issues.
Our formalism had to cover their unit tests.
FILL

%\acks{
%  Thanks to
%  Guido van Rossum for stimulating tweets.
%  This work was partly supported by the US National Science Foundation.
%  This research was also developed with funding from the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL).
%  The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S.~Government.
%  Greenman received support from NSF grant 2030859 to the CRA for the \href{https://cifellows2020.org}{CIFellows} project.
%}


{\sloppy
\printbibliography
}

\appendix

\section{Pyre Limitations}

FILL condense the email thread in comment (see source)

% Pyre limitations
% 4 messages
% Ben Greenman <benjaminlgreenman@gmail.com>	Fri, Sep 24, 2021 at 11:18 AM
% To: Carl Meyer <carljm@fb.com>
% Cc: Dino Viehland <dinoviehland@fb.com>, "Lu, Kuang-Chen" <kuang-chen_lu@brown.edu>, Shriram Krishnamurthi <shriram@gmail.com>
% >>> When we “add types” to a function (by adopting its module into Static
% >>> Python, meaning Static Python now cares about the type annotations on that
% >>> function), there may be other code calling that function with types that
% >>> don’t match what it is annotated to receive. This then causes new runtime
% >>> type errors for those calls once the module is made static. So sometimes we
% >>> do have to fix those – we consider that to be fixing pre-existing type
% >>> errors that Pyre missed. We probably see a lot less of that because the
% >>> codebase is already type annotated and statically checked by Pyre, than we
% >>> would if we were adopting Static Python into a previously-not-type-checked
% >>> codebase.
% >>
% >> I'm surprised that you see any errors like this. Is Pyre unsound at
% >> these pre-existing spots?
% >
% > Yes, Pyre is unsound in various ways (as a purely static checker of a
% > gradually typed language must inherently be):
% >
% > 1. Some code just isn’t covered or checked by Pyre, because Pyre’s gradual
% > adoption strategy is to only check functions that have annotations in their
% > signature, or in extreme cases because the “code” that’s calling into Python
% > isn’t Python code at all, but rather Python C extension code or Cython code.
% > So Pyre has no visibility into calls from code it isn’t even checking.
% > 2. Any code with annotations involving the `Any` type (or missing
% > annotations) will have values that Pyre types as `Any`, and Pyre will
% > silently allow you to do anything with those values. (It has no other
% > choice, this is the only way that static-only gradual typing can work and
% > actually be gradual.) So anything typed as `Any` by Pyre is a potential
% > unsoundness. And although I say our codebase is largely type annotated,
% > given that lots of it is pre-typing code that can’t be accurately statically
% > annotated without rewriting it, there are plenty of Any annotations
% > (especially `Dict[str, Any]` annotations) floating around.
% > 3. People can (and do) just silence Pyre by adding a `# pyre-fixme` comment
% > that silences a type error on the following line, if they are doing some
% > mass adoption of types or otherwise just don’t feel up to fixing a type
% > error for whatever reason. This tends to happen most often in cases where an
% > annotation is just overly restrictive (e.g. claims to require `str` but in
% > fact the method handles `None` just fine, and the argument really should be
% > annotated as `str | None`.) So we have to fix the annotation to actually
% > match the runtime behavior, and then we also are able to remove the
% > pyre-fixme comments; everyone wins :)
% > 4. If the entire codebase and all its type annotations and type stubs agree
% > to lie about some dynamic wrinkle, Pyre will be satisfied that everything is
% > good (and will have no way to know otherwise). A particular case of this we
% > hit recently is that lots of values annotated as `str` in our codebase can
% > actually at runtime be `Promise` objects that dynamically behave like a
% > `str` if you treat them as one, and implement lazy translation of that
% > string to the current user’s language. So as we adopt such code into Static
% > Python, we have to correct those annotations from `str` to `str | Promise`
% > and handle the fallout. A similar case is the `weakref` module in the Python
% > standard library, which allows you to create “weak references” to objects
% > that will not keep them alive in the garbage collector, but will just
% > resolve to None if the object dies. There’s a `weakref.proxy` that creates a
% > transparent weak-reference proxy to any object, and sometimes methods will
% > return one of those but be annotated as returning the proxied type. This is
% > fine for Pyre, as long as the proxy is sufficiently transparent at the level
% > of Python semantics, but it doesn’t work for Static Python.
% 
% Points 1, 2, and 3 make sense.
% 
% I'm wondering if there are ways to write a fully-typed Pyre program (that
% doesn't use those escape hatches) but is still unsound.* It sounds like
% point 4 might be on this track ... but also that unchecked code (points 1,2)
% might be involved.
% 
% For the weakrefs case, would Pyre approve a function like this one:
% 
% ```
%   def f()->C:
%     return weakref.proxy(C())
% ```
% 
% If so, is that because Pyre comes with a builtin annotation for
% `weakrefs.proxy` that lets it return the Any type?
% 
% 
% * For comparison, TypeScript is unsound by design in a few ways. Any computed
% string can index any object. And all object properties are covariant, despite
% being mutable. I wonder if Pyre has similar "static unsoundness" by design.
% Lu, Kuang-Chen <kuang-chen_lu@brown.edu>	Fri, Sep 24, 2021 at 11:50 AM
% To: Ben Greenman <benjaminlgreenman@gmail.com>
% Cc: Shriram Krishnamurthi <shriram@gmail.com>
% (Internal discussion)
% 
% I think point 4, especially the `str` example, comes from the lack of structural typing. Interfaces can partially solve this problem. But with Nom-style interfaces, they have to define an interface and annotate the classes involved.
% [Quoted text hidden]
% Carl Meyer <carljm@fb.com>	Fri, Sep 24, 2021 at 12:37 PM
% To: Ben Greenman <benjaminlgreenman@gmail.com>
% Cc: Dino Viehland <dinoviehland@fb.com>, "Lu, Kuang-Chen" <kuang-chen_lu@brown.edu>, Shriram Krishnamurthi <shriram@gmail.com>
% [Quoted text hidden]
% I think it could be reasonable to define “fully-typed” as to inherently exclude all four points above! This would also exclude most real-world Python programs, but might still be an interesting definition, because even then there are some unsoundnesses remaining (that I didn’t cover above because they are not usually a problem for us in practice; in most cases I think because they involve parts of the type system we don’t even pretend to support yet in Static Python.) I’ll list some of these known unsoundnesses within the type system below.
% 
% In practice the Python language and standard library include features that are considered too painful to use if fully typed, generally because sound typing would require typing things as `object` (the top type), requiring `isinstance` checks everywhere to keep the static checker happy, so an unsound `Any` is preferred for usability reasons. Weakref proxies are just one example of this; there are many others.
% 
% https://github.com/python/typeshed is the shared repository of type stubs for the Python standard library and popular third-party packages (used by all the static checkers: Pyre, mypy, pyright, pytype…). You can search it for `Any` to find many many more examples.
% 
% 
% > For the weakrefs case, would Pyre approve a function like this one:
% >
% > ```
% >  def f()->C:
% >    return weakref.proxy(C())
% > ```
% >
% > If so, is that because Pyre comes with a builtin annotation for
% > `weakrefs.proxy` that lets it return the Any type?
% 
% Yes, exactly, this is in the shared “typeshed” repository: https://github.com/python/typeshed/blob/master/stdlib/_weakref.pyi#L33
% 
% >
% > * For comparison, TypeScript is unsound by design in a few ways. Any computed
% > string can index any object. And all object properties are covariant, despite
% > being mutable. I wonder if Pyre has similar "static unsoundness" by design.
% 
% Right, and the Python type system has some similar unsound-by-design choices. A few that I’m aware of:
% 
% - Mutable attributes ought to be invariant (because they are in effect both getters and setters, thus appearing in both covariant and contravariant position), thus subclasses should not be allowed to change the type of a base class attribute. But in practice all Python type checkers permit a subclass to narrow the type of a base class attribute. Now that `Final[]` annotations are available on attributes (which would make them soundly covariant), it might be more reasonable to close this hole, here’s discussion on the mypy bug tracker: https://github.com/python/mypy/issues/3208. We are currently sound here in Static Python, but in an odd way; we should error on the subclass attribute type override itself, but instead we ignore it and continue to use the base class attribute type for the subclass also.
% 
% - There are some issues with `typing.Type[]` types (these are the types of class objects themselves) and the fact that they are covariant (which is widely relied on.) This is unsound because incompatible constructor signature overriding is allowed in subclasses (which is also widely used). It’s also unsound because the type of the `self` argument to any overridden method will be Parent on the parent method and Child on the child method, which is the opposite of the normal requirement that method arguments (appearing in a contravariant position) must only be widened on subclass overrides. This means that if some function accepts a type and calls an unbound method on it, providing the `self` arg explicitly, the covariance of `Type` is unsound. On these we are currently OK only because we don’t yet support `Type[]` annotations.
% 
% - Type checking argument splatting in calls is unsound. If we have a dynamic list `l` or dict `d` and we have a call like `foo(*l)` or `foo(**d)`, unless foo accepts `(*args, **kwds)` it is impossible to statically type check the call. Making this sound would have to either require the callee to accept (*args, **kwds) or require that the list or dict is a statically known literal; the latter totally defeats the purpose of argument splatting, the former is more conceivable but still makes it a lot less useful, so in practice type checkers just allow these calls. This one is OK in Static Python because we simply fallback to dynamic calls (and thus runtime argument type checks in the callee) for these calls (I mean it’s OK in that it doesn’t result in cascading unsoundness — it still means runtime error rather than static one for the call itself.)
% 
% There are more cases than just these, but I think the others are more esoteric.
% 
% Carl


\end{document}
